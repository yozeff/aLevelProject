#Joseph Harrison 2019
#getting data by webscraping from 
#zoopla database
from lxml import html
import requests
import time
import timeit

URLs = ['https://www.zoopla.co.uk/for-sale/houses/1-bedrooms/uk/?pn=',
        'https://www.zoopla.co.uk/for-sale/houses/2-bedrooms/uk/?pn=',
        'https://www.zoopla.co.uk/for-sale/houses/3-bedrooms/uk/?pn=',
        'https://www.zoopla.co.uk/for-sale/houses/4-bedrooms/uk/?pn=',
        'https://www.zoopla.co.uk/for-sale/houses/5-bedrooms/uk/?pn=']

start = timeit.default_timer()

total = 0
i = 0
while i < len(URLs) and total <= 200:
    site = URLs[i]
    #to get the number of pages, we need to
    #query the first page
    page = requests.get(site + '1')
    tree = html.fromstring(page.content)

    #get the number of pages after a certain url
    #query generated by google chrome, slightly amended to
    #get text from previous 'a' tag
    pages = tree.xpath('//*[@id="content"]/div[7]/a[11]/text()')
    pages = int(pages[0]) 

    for j in range(2, pages):
    
        print(f'j: {j}')

        #get each url linking to a listing
        results = tree.xpath('//a[@class="listing-results-price text-price"]/@href')
        #output these listing urls
        for url in results:

            listingpage = requests.get(f'{site}{j}{url}')
            listingtree = html.fromstring(listingpage.content)

            results = tree.xpath('//span[@class="dp-features-list__text"]/text()')

            print(f'{url} : {len(results)}')
            for entry in results:
                print(entry)

            total += 1

        #we only need to change the page at the
        #end - this way the tree that was generated
        #to get the number of pages doesn't need to
        #be regenerated
        page = requests.get(site + str(j)) 
        tree = html.fromstring(page.content)

    i += 1

end = timeit.default_timer()

print(f'total urls fetched: {total}')
print(f'finsihed in {end - start}s')

